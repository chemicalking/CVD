import streamlit as st
import pandas as pd
import plotly.express as px
from matplotlib import rcParams
from matplotlib import font_manager
import matplotlib.pyplot as plt
import altair as alt
import plotly.figure_factory as ff

# Page configuration
st.set_page_config(
    page_title="NF3 Gas Flow Analysis",
    page_icon="ðŸ‚",
    layout="wide",
    initial_sidebar_state="expanded")
alt.themes.enable("dark")

# è¨­å®šä¸­æ–‡å­—é«”
plt.rcParams['font.sans-serif'] = ['Microsoft JhengHei', 'SimHei', 'Microsoft YaHei', 'Arial Unicode MS']
plt.rcParams['axes.unicode_minus'] = False

# ç¢ºä¿å­—é«”å¯ç”¨
def setup_chinese_font():
    try:
        # å˜—è©¦ä½¿ç”¨æ­£é»‘é«”
        font_path = 'C:/Windows/Fonts/msjh.ttc'  # æ­£é»‘é«”è·¯å¾‘
        font_prop = font_manager.FontProperties(fname=font_path)
        plt.rcParams['font.family'] = font_prop.get_name()
    except:
        try:
            # å˜—è©¦ä½¿ç”¨å¾®è»Ÿé›…é»‘
            font_path = 'C:/Windows/Fonts/msyh.ttc'  # å¾®è»Ÿé›…é»‘è·¯å¾‘
            font_prop = font_manager.FontProperties(fname=font_path)
            plt.rcParams['font.family'] = font_prop.get_name()
        except:
            # å¦‚æžœéƒ½å¤±æ•—ï¼Œä½¿ç”¨ç³»çµ±é»˜èªä¸­æ–‡å­—é«”
            plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'Arial Unicode MS']

setup_chinese_font()

# è¼‰å…¥è³‡æ–™
data = pd.read_csv(r"D:\curso\streamlit\09_app_multipage\data\Merged_Data.csv", encoding='utf-8', sep=',')

# å°‡æ‰€æœ‰æµé‡æ•¸æ“šå››æ¨äº”å…¥åˆ°å°æ•¸é»žå¾Œå…©ä½
flow_columns = ['NF3_total_Flow', 'Daily_Flow_sccm', 'Daily_Flow_kg', 'Daily_Flow_l']
for col in flow_columns:
    if col in data.columns:
        data[col] = data[col].round(2)

# æ‰“å°åˆ—å
st.write("DataFrame åˆ—åï¼š", data.columns.tolist())

data['LAYER'] = data['RECIPEID'].str.extract('(BP|PFA|AS)')

# è‡ªå®šç¾©æ™‚é–“è½‰æ›å‡½æ•¸
def convert_timestamp(ts):
    try:
        ts = str(ts)
        if len(ts) >= 10:  # ç¢ºä¿å­—ç¬¦ä¸²é•·åº¦è¶³å¤ 
            year = ts[:4]
            month = ts[4:6]
            day = ts[6:8]
            hour = ts[8:10] if len(ts) >= 10 else "00"
            return f"{year}/{month}/{day} {hour}:00"
        return None
    except:
        return None

# è½‰æ› TSTAMP æ ¼å¼
data['TSTAMP'] = data['TSTAMP'].apply(convert_timestamp)
data['TSTAMP'] = pd.to_datetime(data['TSTAMP'], format='%Y/%m/%d %H:%M', errors='coerce')

# éŽæ¿¾ step_name ç‚º CLN1ã€CLN2ã€CLN3 çš„æ•¸æ“š
filtered_data = data[data['step_name'].isin(['CLN1', 'CLN2', 'CLN3'])].copy()

# æ·»åŠ æ¯æ—¥æ—¥æœŸæ¬„ä½
filtered_data['Date'] = filtered_data['TSTAMP'].dt.date

# å®šç¾©å–®ä½è½‰æ›å¸¸æ•¸
SCCM_TO_KG = 3.04 / (1000 * 60)
SCCM_TO_LITER = 1 / 60000
SCCM_TO_SCCM = 1

# TreeMap å¯è¦–åŒ–
def visualize_treemap(data):
    st.subheader("Hierarchical view of NF3 Usage (Layer -> RECIPEID -> CHAMBERID)")
    
    tree_data = filtered_data.groupby(['Date','LAYER', 'RECIPEID', 'CHAMBERID'], as_index=False)['NF3_total_Flow'].sum()
    tree_data['NF3_total_Flow'] = tree_data['NF3_total_Flow'].round(2)
    
    fig3 = px.treemap(tree_data, 
                      path=['LAYER', 'RECIPEID', 'CHAMBERID'], 
                      values='NF3_total_Flow', 
                      color='CHAMBERID', 
                      hover_data=['NF3_total_Flow'])
    fig3.update_layout(width=800, height=650)
    fig3.update_traces(textinfo="label+value")
    st.plotly_chart(fig3, use_container_width=True)

# è¨ˆç®—æ¯æ—¥ NF3 ç”¨é‡èˆ‡å–®ç‰‡çŽ»ç’ƒè€—æ°£é‡
def analyze_layer_chamberid(data):
    st.header("LAYER èˆ‡ CHAMBERID åˆ†æž")

    # éŽæ¿¾è¿‘ 30 æ—¥è³‡æ–™
    max_date = data['TSTAMP'].max()
    min_date = max_date - pd.Timedelta(days=30)
    recent_data = data[(data['TSTAMP'] >= min_date) & (data['TSTAMP'] <= max_date)]

    # æ¯æ—¥ NF3 ç”¨é‡è¨ˆç®—
    daily_flow = recent_data.groupby(['LAYER', 'CHAMBERID', recent_data['TSTAMP'].dt.date])['NF3_total_Flow'].sum().reset_index()
    daily_flow['NF3_total_Flow'] = daily_flow['NF3_total_Flow'].round(2)
    daily_flow['Daily_Flow_sccm'] = (daily_flow['NF3_total_Flow'] * SCCM_TO_SCCM).round(2)
    daily_flow['Daily_Flow_kg'] = (daily_flow['NF3_total_Flow'] * SCCM_TO_KG).round(2)
    daily_flow['Daily_Flow_l'] = (daily_flow['NF3_total_Flow'] * SCCM_TO_LITER).round(2)

    # é¡¯ç¤ºæ¯æ—¥ NF3 ç”¨é‡
    st.subheader("æ¯æ—¥ NF3 ç”¨é‡")
    st.dataframe(daily_flow.style.format({
        "NF3_total_Flow": "{:.2f}",
        "Daily_Flow_sccm": "{:.2f}", 
        "Daily_Flow_kg": "{:.2f}", 
        "Daily_Flow_l": "{:.2f}"
    }))

    # å–®ç‰‡çŽ»ç’ƒè€—æ°£é‡
    glassid_count = recent_data.groupby(['CHAMBERID', 'LAYER', recent_data['TSTAMP'].dt.date])['GLASSID'].nunique().reset_index()
    glassid_count = glassid_count.rename(columns={'GLASSID': 'Glass_Count'})
    glass_flow = pd.merge(daily_flow, glassid_count, on=['CHAMBERID', 'LAYER', 'TSTAMP'], how='left')
    glass_flow['Flow_per_Glass_sccm'] = (glass_flow['Daily_Flow_sccm'] / glass_flow['Glass_Count']).round(2)
    glass_flow['Flow_per_Glass_kg'] = (glass_flow['Daily_Flow_kg'] / glass_flow['Glass_Count']).round(2)
    glass_flow['Flow_per_Glass_l'] = (glass_flow['Daily_Flow_l'] / glass_flow['Glass_Count']).round(2)

    st.subheader("å–®ç‰‡çŽ»ç’ƒè€—æ°£é‡")
    st.dataframe(glass_flow.style.format({
        "NF3_total_Flow": "{:.2f}",
        "Daily_Flow_sccm": "{:.2f}", 
        "Daily_Flow_kg": "{:.2f}", 
        "Daily_Flow_l": "{:.2f}",
        "Flow_per_Glass_sccm": "{:.2f}", 
        "Flow_per_Glass_kg": "{:.2f}", 
        "Flow_per_Glass_l": "{:.2f}"
    }))

# å–®æ¬¡ RPSC è€—æ°£é‡åˆ†æž
def analyze_rpsc_usage(data):
    st.header("å–®æ¬¡ RPSC è€—æ°£é‡åˆ†æž")

    # éŽæ¿¾è¿‘ 30 æ—¥è³‡æ–™
    max_date = data['TSTAMP'].max()
    min_date = max_date - pd.Timedelta(days=30)
    recent_data = data[(data['TSTAMP'] >= min_date) & (data['TSTAMP'] <= max_date)]

    # éŽæ¿¾ RPSC è³‡æ–™
    rpsc_data = recent_data[recent_data['RECIPEID'].str.startswith('RPSC')]

    # å–®æ¬¡ RPSC è€—æ°£é‡è¨ˆç®—
    rpsc_daily_flow = rpsc_data.groupby(['CHAMBERID', rpsc_data['TSTAMP'].dt.date])['NF3_total_Flow'].sum().reset_index()
    rpsc_daily_flow['NF3_total_Flow'] = rpsc_daily_flow['NF3_total_Flow'].round(2)
    rpsc_daily_flow['Daily_Flow_sccm'] = (rpsc_daily_flow['NF3_total_Flow'] * SCCM_TO_SCCM).round(2)
    rpsc_daily_flow['Daily_Flow_kg'] = (rpsc_daily_flow['NF3_total_Flow'] * SCCM_TO_KG).round(2)
    rpsc_daily_flow['Daily_Flow_l'] = (rpsc_daily_flow['NF3_total_Flow'] * SCCM_TO_LITER).round(2)

    rpsc_glassid_count = rpsc_data.groupby(['CHAMBERID', rpsc_data['TSTAMP'].dt.date])['GLASSID'].nunique().reset_index()
    rpsc_glassid_count = rpsc_glassid_count.rename(columns={'GLASSID': 'RPSC_Glass_Count'})

    rpsc_usage = pd.merge(rpsc_daily_flow, rpsc_glassid_count, on=['CHAMBERID', 'TSTAMP'], how='left')
    rpsc_usage['Flow_per_RPSC_sccm'] = (rpsc_usage['Daily_Flow_sccm'] / rpsc_usage['RPSC_Glass_Count']).round(2)
    rpsc_usage['Flow_per_RPSC_kg'] = (rpsc_usage['Daily_Flow_kg'] / rpsc_usage['RPSC_Glass_Count']).round(2)
    rpsc_usage['Flow_per_RPSC_l'] = (rpsc_usage['Daily_Flow_l'] / rpsc_usage['RPSC_Glass_Count']).round(2)

    st.subheader("å–®æ¬¡ RPSC è€—æ°£é‡")
    st.dataframe(rpsc_usage.style.format({
        "NF3_total_Flow": "{:.2f}",
        "Daily_Flow_sccm": "{:.2f}", 
        "Daily_Flow_kg": "{:.2f}", 
        "Daily_Flow_l": "{:.2f}",
        "Flow_per_RPSC_sccm": "{:.2f}", 
        "Flow_per_RPSC_kg": "{:.2f}", 
        "Flow_per_RPSC_l": "{:.2f}"
    }))

# Streamlit æ‡‰ç”¨ç¨‹å¼ä¸»é‚è¼¯
def main():
    st.title("NF3 æ°£é«”æµé‡èˆ‡ä½¿ç”¨åˆ†æžå„€è¡¨æ¿")

    # TreeMap å¯è¦–åŒ–
    visualize_treemap(data)

    # LAYER èˆ‡ CHAMBERID åˆ†æž
    analyze_layer_chamberid(data)

    # å–®æ¬¡ RPSC è€—æ°£é‡åˆ†æž
    analyze_rpsc_usage(data)

if __name__ == "__main__":
    main()

